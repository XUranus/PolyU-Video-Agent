# PolyU 视频智能体（PolyU Video Agent）

## 项目背景
**PolyU 视频智能体** 是一个先进的 AI 系统，旨在以视频作为输入，通过内容分析生成上下文感知的回答。本项目致力于满足在多种场景下对智能视频理解日益增长的需求，例如安防监控和教育内容管理。系统能够自动识别视频类型（如监控录像、课程录播等），从而支持用户实现以下功能：

- 查询视频中的特定事件（例如：“监控视频中人物 X 出现在哪些时间点？”）
- 将教学视频按知识点切分为片段，并总结核心内容
- 定位用户指定知识点所对应的视频片段

该系统融合多模态 AI 技术，综合处理视频、音频和文本数据，将原始视频转化为结构化、可检索的知识。

---

## 算法概述
系统核心功能由一套 **Video-RAG（检索增强生成）** 流水线驱动，通过多层次粒度对视频进行处理。具体技术实现如下：

### 框架与模态
- **框架**：LangGraph（用于智能体编排）
- **支持模态**：视频、音频、文本
- **处理流程**：  
  `视频分段 → 粗粒度分析 → 细粒度分析`

### 核心算法步骤
1. **视频分块（Video Chunking）**  
   输入视频根据自适应切割策略被划分为多个时间片段。
2. **语音转文本（Audio-to-Text Conversion）**  
   提取音频轨道并转录为文本，用于语言层面的分析。
3. **粗粒度向量库（Coarse-Grained Vector Store）**  
   为每个视频片段生成高层语义嵌入，用于初步内容检索。
4. **细粒度向量库（Fine-Grained Vector Store）**  
   提取更细致的视觉/听觉特征嵌入，以支持精确的查询匹配。
5. **智能体调度（Agent Scheduling）**  
   LangGraph 负责任务调度与执行，通过动态推理生成上下文相关的回答。

### 工作流图示
```
[视频输入] → [自适应切割策略] → [粗粒度分析]  
                      ↓  
               [细粒度分析] → [智能体调度] → [用户响应]
```
该流水线确保了视觉、听觉和文本数据之间的**时间对齐**，从而支持基于时间戳的精准查询和语义内容检索。

---

## 技术栈
- **前端**：React + TypeScript + Tailwind CSS（构建响应式用户界面）
- **后端**：Python Django（提供 API 服务与任务编排）
- **AI 流水线**：LangGraph、多模态嵌入模型、向量数据库

---

## 典型应用场景
| 场景                | 功能                                                                 |
|---------------------|----------------------------------------------------------------------|
| **安防监控**        | 识别特定人物或事件在监控视频中出现的时间点。                         |
| **教育教学**        | 对课程视频进行知识点切片、内容摘要，并定位对应知识点的视频片段。     |
| **内容审核**        | 通过多模态分析检测不当内容。                                         |

---

## 快速开始（预览版）
```bash
# 前端设置
npm install
npm run dev

# 后端设置
pip install -r requirements.txt
python manage.py runserver
```

*注：完整部署说明将在项目完成后补充。*
